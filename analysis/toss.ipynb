{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvd(p, q):\n",
    "    return 0.5 * np.sum(np.abs(p - q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tvd_for_poisson(stats, lambda_param, special_char='*', temperature=0.7, max_value=20):\n",
    "    counts = Counter(stats[(special_char, lambda_param, temperature)])\n",
    "    total_samples = len(stats[(special_char, lambda_param, temperature)])\n",
    "    empirical_probs = np.array([counts.get(i, 0) / total_samples for i in range(max_value + 1)])\n",
    "    poisson_probs = np.array([poisson.pmf(i, lambda_param) for i in range(max_value + 1)])\n",
    "    return 0.5 * np.sum(np.abs(empirical_probs - poisson_probs))\n",
    "\n",
    "def compute_auc_for_poisson(stats):\n",
    "    symbols = set([k[0] for k in stats.keys()])\n",
    "    lambdas = set([k[1] for k in stats.keys()])\n",
    "    temperatures = set([k[2] for k in stats.keys()])\n",
    "    # Aggregate the TVD scores for each lambda\n",
    "    scores = []\n",
    "    for lambda_param in lambdas:\n",
    "        ls = []\n",
    "        for symbol in symbols:\n",
    "            for temperature in (1.0,):\n",
    "                ls.append(compute_tvd_for_poisson(stats, lambda_param, symbol, temperature))\n",
    "        scores.append(np.mean(ls))\n",
    "\n",
    "    # Compute the AUC\n",
    "    return np.trapezoid(sorted(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc_for_mdp(stats):\n",
    "\n",
    "    true_transition = {\n",
    "        \"1\": [0.0, 0.5, 0.0, 0.5],\n",
    "        \"2\": [0.2, 0.0, 0.8, 0.0],\n",
    "        \"3\": [0.1, 0.2, 0.1, 0.6],\n",
    "        \"4\": [0.1, 0.1, 0.1, 0.7]\n",
    "    }\n",
    "\n",
    "    trajectories_trans = [stats[i:i+1000] for i in range(0, len(stats), 1000)]\n",
    "\n",
    "     # Keep track of local and global indices for each state\n",
    "    idxs_trajectory_transition = []\n",
    "    for global_idx, traj_trans in enumerate(trajectories_trans):\n",
    "        for local_idx, (state, trans) in enumerate(traj_trans):\n",
    "            idxs_trajectory_transition.append(\n",
    "                {\"local_idx\": local_idx,\n",
    "                \"global_idx\": (global_idx * 1000) + local_idx,\n",
    "                \"state\": state,\n",
    "                \"transition\": trans\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Average out a transition at local idx {X} if it is observed at that same point across all trajectories\n",
    "    xy = defaultdict(list)\n",
    "    for state in [\"1\", \"2\", \"3\", \"4\"]:\n",
    "        selected_states = [x for x in idxs_trajectory_transition if x[\"state\"] == state]\n",
    "        local_group = defaultdict(list)\n",
    "        for item in selected_states:\n",
    "            local_group[item[\"local_idx\"]].append(item[\"transition\"])\n",
    "\n",
    "        for k, v in local_group.items():\n",
    "            xy[state].append([k, sum(v) / len(v)])\n",
    "\n",
    "    # Calculate TVD per time step\n",
    "    xys = {}\n",
    "    for state, item in xy.items():\n",
    "        tvds = []\n",
    "        for idx, obs_trans in item:\n",
    "            tvds.append((idx, tvd(true_transition[state], obs_trans)))\n",
    "\n",
    "        xys[state] = tvds\n",
    "\n",
    "    # Calculate AUC for all four states\n",
    "    aucs = []\n",
    "    for state, item in xys.items():\n",
    "        aucs.append(\n",
    "            np.trapezoid(\n",
    "                y=[x[1] for x in sorted(item, key=lambda x: x[0])],\n",
    "                x=[x[0] for x in sorted(item, key=lambda x: x[0])]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return np.mean(aucs) / len(trajectories_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_toss_score(model: str):\n",
    "\n",
    "    # Get the TVD-AUC score for both the coin_flip_multiset and die_roll_multiset experiments\n",
    "    with open(f'../exps/contextual/coin_flip_multiset/{model}/stats.pkl', 'rb') as f:\n",
    "        coin_flip_stats = pickle.load(f)\n",
    "        coin_flip_auc = coin_flip_stats['averaged_stats']['biased_point']['tvd_auc']['mean']\n",
    "    with open(f'../exps/contextual/die_roll_multiset/{model}/stats.pkl', 'rb') as f:\n",
    "        die_roll_stats = pickle.load(f)\n",
    "        die_roll_auc = die_roll_stats['averaged_stats']['biased_point']['tvd_auc']['mean']\n",
    "\n",
    "    # Get the TVD score for the random number experiments\n",
    "    with open(f'../exps/contextual/random_number/{model}/stats.pkl', 'rb') as f:\n",
    "        coin_flip_random_number_stats = pickle.load(f)\n",
    "        auc_data = []\n",
    "        for k, v in coin_flip_random_number_stats['biased_point'].items():\n",
    "            auc_data.append(tvd(v['choice_probs'], np.exp(v[\"expected_dist\"])))\n",
    "        random_number_auc = np.trapezoid(sorted(auc_data))\n",
    "\n",
    "    # MULTINOMIAL\n",
    "    # print(f'TVD-AUC score for coin_flip_multiset: {coin_flip_auc}')\n",
    "    # print(f'TVD-AUC score for die_roll_multiset: {die_roll_auc}')\n",
    "    # print(f'TVD-AUC score for random_number: {random_number_auc}')\n",
    "\n",
    "    # POISSON\n",
    "    with open(f'../exps/poisson/{model}/stats.pkl', 'rb') as f:\n",
    "        poisson_stats = pickle.load(f)\n",
    "        poisson_auc = compute_auc_for_poisson(poisson_stats)\n",
    "\n",
    "    # print(f'TVD-AUC score for poisson: {poisson_auc}')\n",
    "\n",
    "\n",
    "    # Normalizing coefficients\n",
    "\n",
    "\n",
    "\n",
    "    # MDP\n",
    "    # with open(f'/home/ritwik/dev/random_needles/exps/mdp/simple_mdp/{model}/stats.pkl', 'rb') as f:\n",
    "    #     mdp_stats = pickle.load(f)\n",
    "    #     mdp_auc = compute_auc_for_mdp(mdp_stats)\n",
    "    # print(f'TVD-AUC score for MDP: {mdp_auc}')\n",
    "\n",
    "    data = {\n",
    "        \"coin_flip_multiset\": coin_flip_auc / 3.609,\n",
    "        \"die_roll_multiset\": die_roll_auc / 4.104,\n",
    "        \"random_number\": random_number_auc / 0.5023,\n",
    "        \"poisson\": poisson_auc / 1.502,\n",
    "    }\n",
    "\n",
    "    toss_score = 0.4 * data['coin_flip_multiset'] # + 0.4 * data['die_roll_multiset'] + 0.1 * data['random_number'] + 0.1 * data['poisson']\n",
    "\n",
    "    return toss_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google_gemma-2-2b-it: 0.31970926787912196\n",
      "meta-llama_Llama-3.1-8B-Instruct: 0.3486717239011687\n",
      "microsoft_Phi-3.5-mini-instruct: 0.45306309522371246\n",
      "Error for model mistralai_Mistral-7B-Instruct-v0.3: [Errno 2] No such file or directory: '../exps/contextual/die_roll_multiset/mistralai_Mistral-7B-Instruct-v0.3/stats.pkl'\n",
      "allenai_OLMoE-1B-7B-0924-Instruct: 0.477922006022945\n",
      "google_gemma-2-2b: 0.41001955049989036\n",
      "meta-llama_Llama-3.1-8B: 0.37865860832840426\n",
      "microsoft_phi-2: 0.3687636525669912\n",
      "Error for model mistralai_Mistral-7B-v0.3: [Errno 2] No such file or directory: '../exps/contextual/die_roll_multiset/mistralai_Mistral-7B-v0.3/stats.pkl'\n",
      "allenai_OLMoE-1B-7B-0924: 0.443379131998255\n"
     ]
    }
   ],
   "source": [
    "# List of all models being used.\n",
    "# INSTRUCT_MODELS=(\n",
    "#     google/gemma-2-2b-it\n",
    "#     meta-llama/Llama-3.1-8B-Instruct\n",
    "#     microsoft/Phi-3.5-mini-instruct\n",
    "#     mistralai/Mistral-7B-Instruct-v0.3\n",
    "#     allenai/OLMoE-1B-7B-0924-Instruct\n",
    "# )\n",
    "\n",
    "# STD_MODELS=(\n",
    "#     google/gemma-2-2b # TODO\n",
    "#     meta-llama/Llama-3.1-8B # TODO\n",
    "#     microsoft/phi-2\n",
    "#     mistralai/Mistral-7B-v0.3\n",
    "#     allenai/OLMoE-1B-7B-0924\n",
    "# )\n",
    "# /home/davidchan/Repos/random_needles/exps/contextual/coin_flip_multiset/meta-llama_Llama-3.1-8B-Instruct\n",
    "data = []\n",
    "for model in [\n",
    "    'google_gemma-2-2b-it',\n",
    "    'meta-llama_Llama-3.1-8B-Instruct',\n",
    "    'microsoft_Phi-3.5-mini-instruct',\n",
    "    'mistralai_Mistral-7B-Instruct-v0.3',\n",
    "    'allenai_OLMoE-1B-7B-0924-Instruct',\n",
    "    'google_gemma-2-2b',\n",
    "    'meta-llama_Llama-3.1-8B',\n",
    "    'microsoft_phi-2',\n",
    "    'mistralai_Mistral-7B-v0.3',\n",
    "    'allenai_OLMoE-1B-7B-0924'\n",
    "]:\n",
    "    try:\n",
    "        print(f'{model}: {compute_toss_score(model)}')\n",
    "    except Exception as e:\n",
    "        print(f'Error for model {model}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the min, max, and mean for each model across each experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
